{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e09144e-44c2-435d-a145-d74bf5ac4d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from optree->keras->keras-tuner) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mohamed tharif\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/129.1 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/129.1 kB ? eta -:--:--\n",
      "   ------------ -------------------------- 41.0/129.1 kB 245.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 122.9/129.1 kB 654.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 129.1/129.1 kB 543.0 kB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19184744-ceb3-4650-98ed-6454c0889fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Dropout\n",
    "import datetime as dt\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49936d-14f8-4dab-9eef-a2ec19bd6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters\n",
    "prediction_days = 60\n",
    "\n",
    "# Download stock data\n",
    "start_date = dt.datetime(2023, 1, 1)\n",
    "end_date = dt.datetime(2024, 8, 14)\n",
    "stock_data = yf.download('INFY.NS', start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a76cff-d05b-43d4-a5d9-85f6c6d06143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare training data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x - prediction_days:x, 0])\n",
    "    y_train.append(scaled_data[x, 0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d31ae1-bdd9-445b-bb4a-2047c70b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=50, max_value=100, step=10),\n",
    "                   return_sequences=True,\n",
    "                   input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=50, max_value=100, step=10),\n",
    "                   return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_3', min_value=50, max_value=100, step=10)))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(units=25, activation='relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481adfa-d5cb-4d0c-b410-2bb0b8a134fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up Keras Tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=25,\n",
    "                     hyperband_iterations=2,\n",
    "                     directory='my_dir',\n",
    "                     project_name='stock_price_tuning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5eafe-3f31-4b88-86c8-d011860276ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data for validation\n",
    "split = int(0.8 * len(x_train))\n",
    "x_train_split, x_val_split = x_train[:split], x_train[split:]\n",
    "y_train_split, y_val_split = y_train[:split], y_train[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcc50a-188b-4106-b47b-74e903b131e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(x_train_split, y_train_split,\n",
    "             epochs=25,\n",
    "             batch_size=32,\n",
    "             validation_data=(x_val_split, y_val_split))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e8e940-a199-43fd-a78f-39059c3c315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 0.2759\n",
      "Epoch 2/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0788\n",
      "Epoch 3/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0710\n",
      "Epoch 4/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0462\n",
      "Epoch 5/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0389\n",
      "Epoch 6/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0337\n",
      "Epoch 7/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0334\n",
      "Epoch 8/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0205\n",
      "Epoch 9/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0234\n",
      "Epoch 10/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0208\n",
      "Epoch 11/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0170\n",
      "Epoch 12/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0211\n",
      "Epoch 13/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0157\n",
      "Epoch 14/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0137\n",
      "Epoch 15/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0151\n",
      "Epoch 16/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0128\n",
      "Epoch 17/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0123\n",
      "Epoch 18/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0140\n",
      "Epoch 19/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0130\n",
      "Epoch 20/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0117\n",
      "Epoch 21/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0133\n",
      "Epoch 22/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0166\n",
      "Epoch 23/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0130\n",
      "Epoch 24/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0113\n",
      "Epoch 25/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22bc7fd59d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build and compile the best model\n",
    "best_model = build_model(best_hyperparameters)\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6759aff2-b7d0-44b8-9d3c-743128754d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare test data\n",
    "test_data = yf.download('GOOGL', start=dt.datetime(2024, 1, 1), end=dt.datetime(2024, 8, 14))\n",
    "actual_prices = test_data['Close'].values\n",
    "\n",
    "total_dataset = pd.concat((stock_data['Close'], test_data['Close']), axis=0)\n",
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values\n",
    "model_inputs = model_inputs.reshape(-1, 1)\n",
    "model_inputs = scaler.transform(model_inputs)\n",
    "\n",
    "x_test = []\n",
    "for x in range(prediction_days, len(model_inputs)):\n",
    "    x_test.append(model_inputs[x - prediction_days:x, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf5cb95-aacd-4597-9505-5190b4487b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Last actual closing price: 164.16000366210938\n",
      "Last predicted closing price: 1344.5408935546875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predicted_prices = best_model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "# Get the last prediction\n",
    "real_data = model_inputs[-prediction_days:].reshape(1, prediction_days, 1)\n",
    "prediction = best_model.predict(real_data)\n",
    "prediction = scaler.inverse_transform(prediction)\n",
    "\n",
    "# Print results\n",
    "print(f\"Last actual closing price: {actual_prices[-1]}\")\n",
    "print(f\"Last predicted closing price: {prediction[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09172b4-da56-44cf-8d30-274f71d358b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1115.6646324309293\n",
      "Mean Squared Error: 1255457.9461573951\n",
      "Root Mean Squared Error: 1120.4721978511539\n",
      "Mean Absolute Percentage Error (MAPE): 38.19%\n",
      "Accuracy Percentage: 61.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `predicted_prices` and `actual_prices` are your predictions and true values\n",
    "\n",
    "# Calculate MAE, MSE, and RMSE\n",
    "mae = mean_absolute_error(actual_prices[-len(predicted_prices):], predicted_prices)\n",
    "mse = mean_squared_error(actual_prices[-len(predicted_prices):], predicted_prices)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAPE\n",
    "actual_values = actual_prices[-len(predicted_prices):]\n",
    "mape = np.mean(np.abs((actual_values - predicted_prices.flatten()) / actual_values)) * 100\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "accuracy_percentage = 100 - mape\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3370490-6b69-46fd-9fcb-87f55f296bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "best_model.save('D:\\Projects\\ML_Project\\Jupyter NoteBook\\stock_prediction_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
